{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://www.lawrence.edu/fast/greggj/CMSC490/shakespeare.zip\n",
    "#!unzip shakespeare.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the words from the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWord(file):\n",
    "    char = file.read(1)\n",
    "    if not char:\n",
    "        return ''\n",
    "    char = char.lower()\n",
    "\n",
    "    while char < 'a' or char > 'z':\n",
    "        char = file.read(1)        \n",
    "        if not char: \n",
    "            return ''\n",
    "        char = char.lower()\n",
    "\n",
    "    str = ''\n",
    "    while char >= 'a' and char <= 'z':\n",
    "        str = str + char\n",
    "        char = file.read(1)        \n",
    "        if not char: \n",
    "            return str\n",
    "        char = char.lower()\n",
    "    \n",
    "    if char == 'â€™':\n",
    "        str = ''\n",
    "        char = file.read(1)\n",
    "        if not char: \n",
    "            return str\n",
    "        char = char.lower()\n",
    "        while char >= 'a' and char <= 'z':\n",
    "            char = file.read(1)        \n",
    "            if not char: \n",
    "                return str\n",
    "            char = char.lower()\n",
    "        return getWord(file)\n",
    "    return str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting substrings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def makeSubstrings(word):\n",
    "    problem_instances = []\n",
    "    target_values = []\n",
    "    \n",
    "    if len(word) >= 4 and len(word) <= 9:\n",
    "        for i in range(2,len(word)):\n",
    "            if i == len(word)-1:\n",
    "                subword = word\n",
    "                target = ' '\n",
    "            else:\n",
    "                subword = word[0:i]\n",
    "                target = word[i]\n",
    "            problem_instances.append(subword)\n",
    "            target_values.append(target)\n",
    "           \n",
    "    return np.array(problem_instances), np.array(target_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">In the code above the statement target = word[i+1] should be target = word[i]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def makeSequence(str):\n",
    "  if len(str) < 10:\n",
    "    num_padding = 10 - len(str)\n",
    "    for _ in range(0,num_padding):\n",
    "      str = str + \" \"\n",
    "      \n",
    "  onehotarr = []\n",
    "  for ch in str:\n",
    "    onehot = np.array([0] * 27)\n",
    "    \n",
    "    if ch == ' ':\n",
    "      position = 26\n",
    "    else:\n",
    "      position = ord(ch) - ord('a')\n",
    "     \n",
    "    onehot[position] = 1  \n",
    "    onehotarr.append(onehot)\n",
    "  \n",
    "  onehotarr = np.array(onehotarr)\n",
    "\n",
    "  return onehotarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading the text file into the arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n = 100000\n",
    "\n",
    "rawWords = 0\n",
    "with open('shakespeare.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        num = len(line.split())\n",
    "        rawWords += num\n",
    "file.close()\n",
    "\n",
    "words = []\n",
    "problem_instances = []\n",
    "problem_instances = np.array(problem_instances)\n",
    "target_values = []\n",
    "target_values = np.array(target_values)\n",
    "onehot_problems = []\n",
    "onehot_targets = []\n",
    "\n",
    "file = open('shakespeare.txt', 'r')\n",
    "for _ in range(0, rawWords):\n",
    "    word = getWord(file)\n",
    "    words.append(word)\n",
    "file.close()\n",
    "\n",
    "j=0\n",
    "for i in range(0,n):\n",
    "    word = words[j]\n",
    "    problem, target = makeSubstrings(word)\n",
    "    problem_instances = np.concatenate((problem_instances, problem), axis=0)  \n",
    "    target_values = np.concatenate((target_values, target), axis=0)  \n",
    "    j += 1\n",
    "    i += len(problem_instances)\n",
    "    \n",
    "for i in range(0,len(problem_instances)):\n",
    "    oh_prob = makeSequence(problem_instances[i])\n",
    "    oh_tar = makeSequence(target_values[i])\n",
    "    onehot_problems.append(oh_prob)\n",
    "    onehot_targets.append(oh_tar)\n",
    "\n",
    "\n",
    "onehot_problems = np.array(onehot_problems)\n",
    "onehot_targets = np.concatenate(onehot_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">The way you assembled your targets is incorrect. Note that you are using makeSequence() on your targets. That function returns a list of 10 vectors, not 1. This means that you are making ten times as many targets as you need. Further, since your targets consist of a single letter, only the first letter\n",
    "in that sequence of 10 will be a non-space character, while the other 9 will all be spaces. This means that a little over 90% of your target values are the space\n",
    "character. All you will end up doing is training a network to output ' '. If it does that, it will be right more than 90% of the time.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training, Validation, and Test Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.6\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "num_examples = len(onehot_problems)\n",
    "\n",
    "train_end = int(train_ratio * num_examples)\n",
    "validation_end = train_end + int(validation_ratio * num_examples)\n",
    "\n",
    "train_input = onehot_problems[:train_end]\n",
    "train_target = onehot_targets[:train_end]\n",
    "\n",
    "validation_input = onehot_problems[train_end:validation_end]\n",
    "validation_target = onehot_targets[train_end:validation_end]\n",
    "\n",
    "test_input = onehot_problems[validation_end:]\n",
    "test_target = onehot_targets[validation_end:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3452/3452 [==============================] - 21s 6ms/step - loss: 0.4823 - accuracy: 0.9277 - val_loss: 0.4452 - val_accuracy: 0.9307\n",
      "Epoch 2/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4367 - accuracy: 0.9316 - val_loss: 0.4449 - val_accuracy: 0.9307\n",
      "Epoch 3/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4368 - accuracy: 0.9316 - val_loss: 0.4446 - val_accuracy: 0.9307\n",
      "Epoch 4/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4369 - accuracy: 0.9316 - val_loss: 0.4440 - val_accuracy: 0.9307\n",
      "Epoch 5/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4368 - accuracy: 0.9316 - val_loss: 0.4446 - val_accuracy: 0.9307\n",
      "Epoch 6/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4368 - accuracy: 0.9316 - val_loss: 0.4445 - val_accuracy: 0.9307\n",
      "Epoch 7/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4369 - accuracy: 0.9316 - val_loss: 0.4450 - val_accuracy: 0.9307\n",
      "Epoch 8/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4368 - accuracy: 0.9316 - val_loss: 0.4444 - val_accuracy: 0.9307\n",
      "Epoch 9/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4367 - accuracy: 0.9316 - val_loss: 0.4451 - val_accuracy: 0.9307\n",
      "Epoch 10/10\n",
      "3452/3452 [==============================] - 20s 6ms/step - loss: 0.4367 - accuracy: 0.9316 - val_loss: 0.4451 - val_accuracy: 0.9307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d70171ea0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(16, input_shape=(10, 27), return_sequences=False))\n",
    "model.add(Dense(27, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit( \n",
    "    train_input, train_target,\n",
    "    validation_data=(validation_input, validation_target),\n",
    "    epochs=10,  \n",
    "    batch_size=32  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 110ms/step\n",
      "a\n",
      "[[1.4934370e-03 2.0491339e-04 1.1166770e-03 2.3804887e-03 1.5634406e-02\n",
      "  7.5066154e-04 2.4627792e-03 3.4647384e-03 2.2556472e-03 4.2907773e-06\n",
      "  6.4736319e-04 3.0154707e-03 1.2844884e-03 4.1956315e-03 1.4564706e-03\n",
      "  7.4128521e-04 5.0564493e-05 6.0058879e-03 6.5865442e-03 7.5003323e-03\n",
      "  3.0027020e-03 6.3747924e-04 6.5228558e-04 1.0580634e-05 1.5125592e-03\n",
      "  2.1872482e-05 9.3291050e-01]]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(np.array([makeSequence('hous')]))\n",
    "print(chr(ord('a')))\n",
    "print(p)\n",
    "#it seems to always pick the space as the most probable outcome. I don't know why so I'm just taking comfort in the fact that at least the second best p is the correct guess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">Mostly correct, with one very big mistake. See the comment above for details. 77/80</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
